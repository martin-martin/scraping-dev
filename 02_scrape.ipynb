{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Scrape HTML Content From a Page\n",
    "\n",
    "- **Static Websites**\n",
    "- _Hidden Websites_\n",
    "- _Dynamic Websites_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.indeed.com/jobs?q=python&l=new+york\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta http-equiv=\"content-type\" content=\"text/html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:100]  # let's take a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response.content).find('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'?q=python&l'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[390:401]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tedious and inefficient! That's where **parsing** comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Websites\n",
    "\n",
    "Some pages require you to log in before they display information. Scraping them _without_ logging in doesn't give you what you want. `requests` includes ways to authenticate with websites.\n",
    "\n",
    "Train this with [GitHub](https://github.com/) and our tutorial on [Python's Requests Library](https://realpython.com/python-requests/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Websites\n",
    "\n",
    "Websites attempt to offload computing power to the client. That means they send back **JavaScript** code that the client's browser executes.\n",
    "\n",
    "These pages are harder to scrape, because that code needs to be executed before you will see the information you are interested in.\n",
    "\n",
    "Train this with [requests-html](https://html.python-requests.org/) or [Selenium](https://selenium-python.readthedocs.io/) and our tutorial for [Modern Web Automation with Python and Selenium](https://realpython.com/modern-web-automation-with-python-and-selenium/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
